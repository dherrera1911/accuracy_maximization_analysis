{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f151012e",
   "metadata": {},
   "source": [
    "#Disparity estimation and filter training in pairs\n",
    "\n",
    "Train AMA on the task of disparity estimation. Train two\n",
    "pairs of filters, one after the other (first the model\n",
    "with 2 filters, and then the model with 4 filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fedf53f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### IMPORT PACKAGES\n",
    "##############\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20555bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### COMMENT THIS CELL WHEN USING GOOGLE COLAB\n",
    "#from ama_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2eb7fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### UNCOMMENT THIS CELL FOR GOOGLE COLAB EXECUTION\n",
    "!pip install geotorch\n",
    "import geotorch\n",
    "!pip install git+https://github.com/dherrera1911/accuracy_maximization_analysis.git\n",
    "from ama_library import *\n",
    "!mkdir data\n",
    "!wget -O ./data/AMAdataDisparity.mat https://github.com/burgelab/AMA/blob/master/AMAdataDisparity.mat?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57adb5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### LOAD AMA DATA\n",
    "##############\n",
    "# Load ama struct from .mat file into Python\n",
    "data = spio.loadmat('./data/AMAdataDisparity.mat')\n",
    "# Extract contrast normalized, noisy stimulus\n",
    "s = data.get(\"s\")\n",
    "s = torch.from_numpy(s)\n",
    "s = s.transpose(0,1)\n",
    "s = s.float()\n",
    "# Extract the vector indicating category of each stimulus row\n",
    "ctgInd = data.get(\"ctgInd\")\n",
    "ctgInd = torch.tensor(ctgInd)\n",
    "ctgInd = ctgInd.flatten()\n",
    "ctgInd = ctgInd-1       # convert to python indexing (subtract 1)\n",
    "ctgInd = ctgInd.type(torch.LongTensor)  # convert to torch integer\n",
    "# Extract the values of the latent variable\n",
    "ctgVal = data.get(\"X\")\n",
    "ctgVal = torch.from_numpy(ctgVal)\n",
    "ctgVal = ctgVal.flatten()\n",
    "nPixels = int(s.shape[1]/2)\n",
    "# Extract Matlab trained filters\n",
    "fOri = data.get(\"f\")\n",
    "fOri = torch.from_numpy(fOri)\n",
    "fOri = fOri.transpose(0,1)\n",
    "fOri = fOri.float()\n",
    "# Extract original noise parameters\n",
    "filterSigmaOri = data.get(\"var0\").flatten()\n",
    "maxRespOri = data.get(\"rMax\").flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36769d95",
   "metadata": {},
   "source": [
    "## TEST HOW REPRODUCIBLE THE LEARNED FILTERS ARE, AND TRY DIFFERENT LEARNING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66af4e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### Set the parameters for training the models\n",
    "##############\n",
    "\n",
    "nPairs = 4   # Number of filters to use\n",
    "filterSigma = float(filterSigmaOri / maxRespOri**2)  # Variance of filter responses\n",
    "nEpochs = 50\n",
    "lrGamma = 0.5   # multiplication factor for lr decay\n",
    "lossFun = nn.CrossEntropyLoss()\n",
    "learningRate = 0.02\n",
    "lrStepSize = 10\n",
    "batchSize = 1024\n",
    "\n",
    "# Put data into Torch data loader tools\n",
    "trainDataset = TensorDataset(s, ctgInd)\n",
    "# Batch loading and other utilities \n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=batchSize,\n",
    "        shuffle=True)\n",
    "\n",
    "# Function that returns an optimizer\n",
    "def opt_fun(model):\n",
    "    return torch.optim.Adam(model.parameters(), lr=learningRate)\n",
    "# Function that returns a scheduler\n",
    "def scheduler_fun(opt):\n",
    "    return optim.lr_scheduler.StepLR(opt, step_size=lrStepSize, gamma=lrGamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f32f5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### Train an initial model several times, see filter variability\n",
    "##############\n",
    "\n",
    "nModels = 4\n",
    "loss = [None] * nModels\n",
    "finalLosses = np.zeros((nModels, nPairs))\n",
    "elapsedTimes = [None] * nModels\n",
    "filters = [None] * nModels\n",
    "for n in range(nModels):\n",
    "    amaPy = AMA(sAll=s, nFilt=2, ctgInd=ctgInd, filterSigma=filterSigma,\n",
    "        ctgVal=ctgVal)\n",
    "    loss[n], elapsedTimes[n] = fit_by_pairs(nEpochs=nEpochs, model=amaPy,\n",
    "        trainDataLoader=trainDataLoader, lossFun=lossFun, opt_fun=opt_fun,\n",
    "        nPairs=nPairs, scheduler_fun=scheduler_fun)\n",
    "    filters[n] = amaPy.fixed_and_trainable_filters().detach().clone()\n",
    "    for p in range(nPairs):\n",
    "        finalLosses[n, p] = loss[n][p][-1]\n",
    "\n",
    "# Print the loss of the model after each pair of filters is learned.\n",
    "# Columns indicate the pair of filters, and rows indicate the model instance\n",
    "print(finalLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ece4c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### Train an initial model several times, see filter variability\n",
    "##############\n",
    "# Plot the learned filters\n",
    "nFilt = 8\n",
    "for n in range(nModels):\n",
    "    for nf in range(nFilt):\n",
    "        plt.subplot(nModels, nFilt, n*nFilt + nf + 1)\n",
    "        view_filters_bino(filters[n][nf,:])\n",
    "        plt.yticks([])\n",
    "        plt.xticks([])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
