{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "910d9986",
   "metadata": {},
   "source": [
    "# Tutorial of the AMA-Gauss Python package\n",
    "\n",
    "Accuracy Maximization Analysis (AMA) is a **dimensionality reduction**\n",
    "technique that learns a set of optimal linear\n",
    "features to solve a **classification task**,\n",
    "given a **Bayesian decoder** of the filter responses. AMA-Gauss\n",
    "is a variant of AMA that assumes Gaussian conditional distributions\n",
    "of the features (we'll refer to AMA-Gauss as AMA throghout).\n",
    "\n",
    "AMA has been used to train image-computable **ideal observer models**\n",
    "for different visual tasks (estimation of retinal speed,\n",
    "disparity, 3D motion, defocus).\n",
    "Unlike other ideal observer models (i.e. models\n",
    "using optimal probabilistic inference to solve a perceptual task),\n",
    "AMA is image-computable. That is,\n",
    "while most ideal observers receive as input a noisy estimate of\n",
    "the latent variable of interest (without specifying how it is\n",
    "estimated from the raw input), AMA receives the raw\n",
    "high-dimensional image and uses it to estimate the latent variable.\n",
    "\n",
    "Unlike other models used to learn optimal sensory\n",
    "encodings of natural image statistics which use efficient\n",
    "coding, or reconstruction error (e.g. sparse coding), AMA learns the\n",
    "optimal encoding to solve a specific sensory tasks.\n",
    "\n",
    "Here we introduce a PyTorch implementation of AMA, trained through\n",
    "gradient descent.\n",
    "We present the mathematical formalism of the model, the different\n",
    "components of AMA class, and the\n",
    "functionalities to train and test an AMA model on a set of stimuli.\n",
    "As an study case, we train AMA on the task of disparity estimation from\n",
    "binocular images.\n",
    "\n",
    "## Basic structure of AMA-Gauss\n",
    "\n",
    "Let $\\mathbf{s}_{i,j} \\in \\mathbb{R}^d$ be an input stimulus\n",
    "(e.g. a binocular image) that is the $i^{th}$ stimulus associated\n",
    "the true value $X_j$ of the latent variable $X$\n",
    "(e.g. the disparity of the image).\n",
    "The latent variable can take values (e.g. a given disparity value in\n",
    "arc min) from a set ${X_1, X_2, ..., X_k}$.\n",
    "The goal of AMA is to compute the\n",
    "posterior probability distribution over $X$, which can be used to read out\n",
    "an estimate of the latent variable for the input image. This will be made\n",
    "clearer below.\n",
    "\n",
    "The AMA-Gauss model consists of 3 stages:\n",
    "\n",
    "1. Noisy encoding of the stimulus and contrast normalization\n",
    "1. Apply noisy linear filters to the noisy normalized stimulus\n",
    "1. Computing the posterior distribution over the latent variable\n",
    "      from the filter responses\n",
    "\n",
    "**1)** First, because the stimulus is encoded by noisy sensory receptors,\n",
    "we add a sample of white noise. Then we normalize to unit lenght.\n",
    "$\\gamma \\in \\mathbb{R}^d, \\gamma \\sim \\mathcal{N}\\left(0,\\sigma_s^2 \\right)$\n",
    "to the stimulus. Then, we contrast normalize the noisy stimulus:\n",
    "\\begin{equation}\n",
    "  \\mathbf{c}_{i,j} = \\frac{\\mathbf{s}_{i,j}+\\mathbf{\\gamma}}{\\lVert\n",
    "      \\mathbf{s}_{i,j}+ \\mathbf{\\gamma} \\rVert}\n",
    "\\end{equation}\n",
    "\n",
    "**2)** Next, we apply a set of noisy linear filters\n",
    "$\\mathbf{f} \\in \\mathbb{R}^{n \\times d}$ to\n",
    "the contrast-normalized stimulus to obtain a noisy response vector\n",
    "$\\mathbf{R}_{i,j} \\in \\mathbb{R}^n$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{R}_{i,j} = \\mathbf{f} \\cdot \\mathbf{c}_{i,j} + \\eta\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta \\in \\mathbb{R}^n, \\eta \\sim \\mathcal{N}\\left(0, \\sigma_0^2 \\right)$\n",
    "is a sample of white noise.\n",
    "\n",
    "**3)** Finally, we obtain the posterior probabilities of each value of the latent\n",
    "variable, given the filter responses, $P(X=X_m|\\mathbf{R}_{i,j})$. For this we\n",
    "compute the likelihood functions\n",
    "$L(X=X_m;\\mathbf{R}_{i,j}) = P(\\mathbf{R}_{i,j}|X_m)$\n",
    "and combine them with the class priors $P(X_m)$:\n",
    "\n",
    "\\begin{equation}\n",
    "  P(X=X_m|\\mathbf{R}_{i,j}) = L(X=X_m; \\mathbf{R}_{i,j}) P(X=X_m) $$\n",
    "\\end{equation}\n",
    "\n",
    "The details of the probabilistic model to decode the lateng variable\n",
    "are explained below.\n",
    "\n",
    "In the tutorial, we train an AMA model on a set of binocular images to solve\n",
    "the task of estimating disparity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82012f2f",
   "metadata": {},
   "source": [
    "## 1) Import and visualize the data\n",
    "\n",
    "We first download and import the binocular images and their\n",
    "disparity values from the [Burge lab](http://burgelab.psych.upenn.edu/) GitHub page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84224247",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### IMPORT PACKAGES\n",
    "##############\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377d8f45",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### IMPORT DISPARITY DATA FROM BURGE LAB GITHUB\n",
    "#!mkdir data\n",
    "#!wget -O ./data/AMAdataDisparity.mat https://drive.google.com/file/d/17LA4E3F4xrEUnNWOA_jesiSCkDah5asd/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570d7c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### LOAD DISPARITY DATA\n",
    "##############\n",
    "# Load ama struct from .mat file into Python\n",
    "data = spio.loadmat('./data/ama_dsp_noiseless.mat')\n",
    "# Extract disparity stimuli\n",
    "s = data.get(\"s\")\n",
    "s = torch.from_numpy(s)\n",
    "s = s.transpose(0,1)\n",
    "s = s.float()\n",
    "# Get number of pixels\n",
    "nPixels = int(s.shape[1]/2)\n",
    "# Extract the vector indicating category of each stimulus row\n",
    "ctgInd = data.get(\"ctgInd\")\n",
    "ctgInd = torch.tensor(ctgInd)\n",
    "ctgInd = ctgInd.flatten()\n",
    "ctgInd = ctgInd-1       # convert to python indexing (subtract 1)\n",
    "ctgInd = ctgInd.type(torch.LongTensor)  # convert to torch integer\n",
    "# Extract the values of the latent variable\n",
    "ctgVal = data.get(\"X\")\n",
    "ctgVal = torch.from_numpy(ctgVal)\n",
    "ctgVal = ctgVal.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106416cc",
   "metadata": {},
   "source": [
    "We loaded the binocular images into variable `s`. \n",
    "The stimuli that we loaded are vertically-averaged versions\n",
    "of the original stimuli, and thus are 1D images\n",
    "(see Burge and Geisler JoV 2014 for details).\n",
    "\n",
    "We loaded into variable `ctgInd` a vector containing the index $j$ of the\n",
    "true level $X_j$ of the latent variable $X$ associated with each stimulus.\n",
    "In `ctgVal` we loaded the set of possible levels\n",
    "that $X$ can take.\n",
    "\n",
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb52f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Image dataset s has {s.shape[0]} images, of {s.shape[1]} pixels each ({nPixels} pixels per monocular image)')\n",
    "print(f'ctgInd is a vector of length {len(ctgInd)}, with the category index of each s')\n",
    "print(f'ctgVal is a vector of length {len(ctgVal)} containing the possible values of X')\n",
    "print(f'ctgVal ranges between {min(ctgVal)} and {max(ctgVal)} arcmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a363f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LETS PLOT A RANDOM STIMULUS AND SHOW ITS DISPARITY\n",
    "arcMin = np.linspace(start=-30, stop=30, num=nPixels) # x axis values\n",
    "randomInd = np.random.randint(s.shape[0])  # Select a random stimulus\n",
    "# Get the disparity value\n",
    "stimCategoryInd = ctgInd[randomInd]  # select category index (j) for this stim\n",
    "stimDisparity = ctgVal[stimCategoryInd].numpy()  # Get value of the category (X_j)\n",
    "# Plot the binocular 1D images\n",
    "x = np.linspace(-30, 30, nPixels)\n",
    "plt.plot(x, s[randomInd, :nPixels], label='Left', color='red')  # plot left eye\n",
    "plt.plot(x, s[randomInd, nPixels:], label='Right', color='blue')  #plot right eye\n",
    "plt.ylabel('Weber contrast')\n",
    "plt.xlabel('Visual field (arcmin)')\n",
    "plt.title(f'Stimulus {randomInd}, with j={stimCategoryInd}, $X_j$={stimDisparity} arc min disparity')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9194784",
   "metadata": {},
   "source": [
    "We saw above the main inputs that the model will receive:\n",
    "the stimuli matrix `s`, their latent variable indices `ctgInd`, and\n",
    "the latent variable values `ctgVal`. Next, we'll see the structure of the\n",
    "AMA-Gauss model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30ced7",
   "metadata": {},
   "source": [
    "## 2) Download AMA library and initialize AMA object\n",
    "\n",
    "The ama_library (under development) can be found in\n",
    "https://github.com/dherrera1911/accuracy_maximization_analysis.\n",
    "We download and import the library below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f4c08",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First we need to download and install geotorch\n",
    "#!pip install geotorch\n",
    "#import geotorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6c0ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INSTALL THE AMA_LIBRARY PACKAGE FROM GITHUB\n",
    "#!pip install git+https://github.com/dherrera1911/accuracy_maximization_analysis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6ec0b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORT THE AMA LIBRARY\n",
    "import ama_library.ama_class as cl\n",
    "import ama_library.utilities as au\n",
    "import ama_library.quadratic_moments as qm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66fe05",
   "metadata": {},
   "source": [
    "In the ama_library, the ama_class module implements the AMA class, which\n",
    "is built on top of the nn.Module from PyTorch. We initialize an AMA\n",
    "object to estimate disparity from binocular image patches.\n",
    "\n",
    "The input parameters to generate the AMA object (mentioned in the\n",
    "AMA formulas above):\n",
    "\n",
    "* Number of filters: $n$ in the equations, `nFilt` input\n",
    "* Pixel noise variance: $\\sigma_s^2$ in the equations, `pixelCov` input\n",
    "* Response noise variance: $\\sigma_0^2$ in the equations, `respNoiseVar` input\n",
    "\n",
    "We need to pass the training dataset as input (the matrix with\n",
    "$\\mathbf{s}$, the vector with associated indexes\n",
    "$j$, and the latent variable values $X_j$).\n",
    "This is because the statistics of the stimulus and of filter responses\n",
    "are stored in the AMA object. Thus, the training dataset is used to\n",
    "estimate the statistics for the initial random filters\n",
    "\n",
    "Let's initialize the AMA model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c417dcbf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "nFilt = 2  # Create the model with 2 filters\n",
    "pixelNoiseVar = 0.02  # Input pixel noise variance\n",
    "respNoiseVar = 0.2  # Filter response noise variance\n",
    "# Create the untrained AMA object\n",
    "ama = cl.AMA(sAll=s, ctgInd=ctgInd, nFilt=nFilt, respNoiseVar=respNoiseVar,\n",
    "        pixelCov=pixelNoiseVar, ctgVal=ctgVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88446a8b",
   "metadata": {},
   "source": [
    "Let's list some of the basic attributes of the AMA class.\n",
    "\n",
    "**Attributes:**\n",
    "* nFilt: Number of filters in the model ($n$ in the equations)\n",
    "* nDim: Number of dimensions in $s$ ($d$ in the equations)\n",
    "* nClasses: Number of latent variable levels ($k$ in the equations)\n",
    "* f: Filters. Initialized to random variables, these are the trainable\n",
    "      parameters, and are constrained to have unit norm.\n",
    "      ($\\in \\mathbb{R}^{n \\times d}$).\n",
    "* ctgVal: Values of the latent variable ($X_1, X_2, ..., X_k$).\n",
    "      ($\\in \\mathbb{R}^{k}$).\n",
    "* stimCov: Covariance matrices for the noisy normalized stimuli\n",
    "      $\\mathbf{c}$ of each class $X=X_j$.\n",
    "      ($\\mathbf{\\Psi} \\in \\mathbb{R}^{k \\times d \\times d}$).\n",
    "* stimMean: Means for the noisy-normalized stimuli $\\mathbf{c}$ of each class.\n",
    "      ($\\mathbf{mu} \\in \\mathbb{R}^{k \\times d}$)\n",
    "* respCov: Covariance matrices for the noisy responses $\\mathbf{R}_{i,j}$\n",
    "      (including stimulus variability and filter noise).\n",
    "      ($\\in \\mathbb{R}^{k \\times n \\times n}$. \n",
    "* respMean: Means for the noisy responses $\\mathbf{R}_{i,j}$.\n",
    "      ($\\in \\mathbb{R}^{k \\times n}$.\n",
    "\n",
    "Let's verify that the statistics present in the AMA model match\n",
    "what we would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf6789",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First visualize randomly initialized filters\n",
    "fInit = ama.f.detach().clone()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, fInit[0, :nPixels], label='Left', color='red')  # plot left eye\n",
    "plt.plot(x, fInit[0, nPixels:], label='Right', color='blue')  #plot right eye\n",
    "plt.ylabel('Weight')\n",
    "plt.xlabel('Visual field (arcmin)')\n",
    "plt.title(f'Filter 1, random init')\n",
    "plt.ylim(-0.4, 0.4)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, fInit[1, :nPixels], label='Left', color='red')  # plot left eye\n",
    "plt.plot(x, fInit[1, nPixels:], label='Right', color='blue')  #plot right eye\n",
    "plt.xlabel('Visual field (arcmin)')\n",
    "plt.title(f'Filter 2, random init')\n",
    "plt.ylim(-0.4, 0.4)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c24cf5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COMPUTE THE COVARIANCE OF THE NOISY NORMALIZED STIMULI FOR CATEGORY j=3\n",
    "# BY SIMULATION\n",
    "#\n",
    "# Load useful functions\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Extract the stimuli s for the category\n",
    "j = 3  # Index of the category to analyze\n",
    "stimInds = torch.where(ctgInd==j)[0]  # Get indices of the stimuli\n",
    "sj = s[stimInds, ]  # Extract the stimuli of class j\n",
    "\n",
    "# ADD NOISE SAMPLES. FOR BETTER POWER, WE ADD MANY NOISE SAMPLES PER STIMULUS\n",
    "# Make the matrix of pixel covariance noise\n",
    "pixelNoiseCov = torch.eye(sj.shape[1]) * pixelNoiseVar  # Covariance of stim noise\n",
    "# Random noise generator\n",
    "noiseDistr = MultivariateNormal(loc=torch.zeros(sj.shape[1]),\n",
    "        covariance_matrix=pixelNoiseCov)\n",
    "# Number of noisy samples to generate for each stimulus\n",
    "samplesPerStim = 20\n",
    "# Repeat class stimuli to use many noise samples\n",
    "repStim = sj.repeat(samplesPerStim, 1)\n",
    "# Add noise\n",
    "noisyStim = repStim + noiseDistr.rsample([repStim.shape[0]])\n",
    "# Normalize to unit norm\n",
    "noisyNormStim = F.normalize(noisyStim, p=2, dim=1)\n",
    "# Apply the initialized filters\n",
    "responses = torch.matmul(noisyNormStim, fInit.transpose(0, 1))\n",
    "\n",
    "# COMPUTE THE COVARIANCES OF STIMULI AND NOISE\n",
    "stimCovEmpirical = torch.cov(noisyNormStim.transpose(0,1))\n",
    "respCovEmpirical = torch.cov(responses.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ec688",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize empirically obtained covariances and the ones present in\n",
    "# the ama object (which are computed analytically)\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(stimCovEmpirical)\n",
    "plt.title('Cov(s) [empirical]')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(ama.stimCov[j,:,:].detach())\n",
    "plt.title('Cov(s) [AMA]')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(respCovEmpirical)\n",
    "plt.title('Cov(R) [empirical]')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(ama.respCov[j,:,:].detach())\n",
    "plt.title('Cov(R) [AMA]')\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Stimulus and response covariance for one class. Empirical vs AMA')\n",
    "plt.setp(fig.get_axes(), xticks=[], yticks=[])\n",
    "fig.set_size_inches(7,3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
