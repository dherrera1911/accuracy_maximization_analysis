{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1e0b2d1",
   "metadata": {},
   "source": [
    "#Disparity estimation and effect of batch size\n",
    "\n",
    "Train AMA on the task of disparity estimation. Compare\n",
    "the filters learned with different batch sizes, as well\n",
    "as model performance and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d485e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### IMPORT PACKAGES\n",
    "##############\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8b4ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### COMMENT THIS CELL WHEN USING GOOGLE COLAB\n",
    "import geotorch\n",
    "from ama_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023c3c0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### UNCOMMENT THIS CELL FOR GOOGLE COLAB EXECUTION\n",
    "#!pip install geotorch\n",
    "#import geotorch\n",
    "#!pip install git+https://github.com/dherrera1911/accuracy_maximization_analysis.git\n",
    "#from ama_library import *\n",
    "#!mkdir data\n",
    "#!wget -O ./data/AMAdataDisparity.mat https://github.com/burgelab/AMA/blob/master/AMAdataDisparity.mat?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b12f5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### LOAD AMA DATA\n",
    "##############\n",
    "# Load ama struct from .mat file into Python\n",
    "data = spio.loadmat('./data/AMAdataDisparity.mat')\n",
    "# Extract contrast normalized, noisy stimulus\n",
    "s = data.get(\"s\")\n",
    "s = torch.from_numpy(s)\n",
    "s = s.transpose(0,1)\n",
    "s = s.float()\n",
    "# Extract the vector indicating category of each stimulus row\n",
    "ctgInd = data.get(\"ctgInd\")\n",
    "ctgInd = torch.tensor(ctgInd)\n",
    "ctgInd = ctgInd.flatten()\n",
    "ctgInd = ctgInd-1       # convert to python indexing (subtract 1)\n",
    "ctgInd = ctgInd.type(torch.LongTensor)  # convert to torch integer\n",
    "# Extract the values of the latent variable\n",
    "ctgVal = data.get(\"X\")\n",
    "ctgVal = torch.from_numpy(ctgVal)\n",
    "ctgVal = ctgVal.flatten()\n",
    "nPixels = int(s.shape[1]/2)\n",
    "# Extract Matlab trained filters\n",
    "fOri = data.get(\"f\")\n",
    "fOri = torch.from_numpy(fOri)\n",
    "fOri = fOri.transpose(0,1)\n",
    "# Extract original noise parameters\n",
    "filterSigmaOri = data.get(\"var0\").flatten()\n",
    "maxRespOri = data.get(\"rMax\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af04fdc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### SET TRAINING PARAMETERS\n",
    "##############\n",
    "nFilt = 2 # Number of filters to use\n",
    "filterSigma = float(filterSigmaOri / maxRespOri**2) # Variance of filter responses\n",
    "nEpochs = 50\n",
    "learningRateBase = 0.004\n",
    "# Choose loss function\n",
    "lossFun = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc99c3fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### FIT AMA WITH DIFFERENT BATCH SIZES\n",
    "##############\n",
    "nStim = s.shape[0]\n",
    "batchFractions = np.array([1/50, 1/20, 1/10, 1/5, 1])\n",
    "nBatchSizes = batchFractions.size\n",
    "batchSizeVec = (nStim*batchFractions).astype(int)\n",
    "\n",
    "filterDict = {\"batchSize\": [], \"filter\": [], \"loss\": [], 'time': [],\n",
    "        'estimates': [], 'estimateStats': []}\n",
    "\n",
    "for bs in range(nBatchSizes):\n",
    "    learningRate = learningRateBase * np.sqrt(10 * batchFractions[bs])\n",
    "    batchSize = int(batchSizeVec[bs])\n",
    "    # Initialize model with random filters\n",
    "    amaPy = AMA(sAll=s, ctgInd=ctgInd, nFilt=nFilt, filterSigma=filterSigma,\n",
    "            ctgVal=ctgVal)\n",
    "    # Add norm 1 constraint (set parameters f to lay on a sphere)\n",
    "    geotorch.sphere(amaPy, \"f\")\n",
    "    # Put data into Torch data loader tools\n",
    "    trainDataset = TensorDataset(s, ctgInd)\n",
    "    # Batch loading and other utilities \n",
    "    trainDataLoader = DataLoader(trainDataset, batch_size=batchSize,\n",
    "            shuffle=True)\n",
    "    # Set up optimizer\n",
    "    opt = torch.optim.Adam(amaPy.parameters(), lr=learningRate)  # Adam\n",
    "    #opt = torch.optim.SGD(amaPy.parameters(), lr=0.03)  # SGD\n",
    "    # fit model\n",
    "    loss, elapsedTimes = fit(nEpochs=nEpochs, model=amaPy,\n",
    "            trainDataLoader=trainDataLoader, lossFun=lossFun, opt=opt)\n",
    "    # Store ama information into dictionary\n",
    "    filterDict[\"batchSize\"].append(batchSize)\n",
    "    filterDict[\"filter\"].append(amaPy.f.detach())\n",
    "    filterDict[\"loss\"].append(loss)\n",
    "    filterDict[\"time\"].append(elapsedTimes)\n",
    "    filterDict[\"estimates\"].append(amaPy.get_estimates(s))\n",
    "    filterDict[\"estimateStats\"].append(\n",
    "            get_estimate_statistics(filterDict[\"estimates\"][bs], ctgInd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021731ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# DEFINE A FUNCTION TO VISUALIZE BINOCULAR FILTERS\n",
    "def view_filters_bino(f, x=[], title=''):\n",
    "    plt.title(title)\n",
    "    nPixels = int(max(f.shape)/2)\n",
    "    if len(x) == 0:\n",
    "        x = np.arange(nPixels)\n",
    "    plt.plot(x, f[:nPixels], label='L', color='red')\n",
    "    plt.plot(x, f[nPixels:], label='R', color='blue')\n",
    "    plt.ylim(-0.3, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e4026",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the first 2 filters for each batch size\n",
    "x = np.linspace(start=-30, stop=30, num=nPixels) # x axis in arc min\n",
    "for bs in range(nBatchSizes):\n",
    "    plt.subplot(2, nBatchSizes, bs+1)\n",
    "    # Plot filter 1\n",
    "    f1 = filterDict[\"filter\"][bs][0,:]\n",
    "    view_filters_bino(f=f1, x=x, title='size: %i'  %batchSizeVec[bs])\n",
    "    plt.subplot(2, nBatchSizes, bs+1+nBatchSizes)\n",
    "    # Plot filter 2\n",
    "    f2 = filterDict[\"filter\"][bs][1,:]\n",
    "    view_filters_bino(f=f2, x=x, title=''  %batchSizeVec[bs])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcddcbc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the learning curve for each batch size\n",
    "minLoss = 2.6 # Lower limit of y axis\n",
    "maxTime = 5   # Upper limit of X axis in the time plot\n",
    "for bs in range(nBatchSizes):\n",
    "    plt.subplot(2, nBatchSizes, bs+1)\n",
    "    loss = filterDict[\"loss\"][bs]\n",
    "    time = filterDict[\"time\"][bs]\n",
    "    plt.plot(time, loss)\n",
    "    plt.ylim(minLoss, 2.98)\n",
    "    plt.xlim(0, maxTime)\n",
    "    plt.ylabel('Cross entropy loss')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.title('size: %i'  %batchSizeVec[bs])\n",
    "    if bs>0:\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('')\n",
    "    plt.subplot(2, nBatchSizes, bs+1+nBatchSizes)\n",
    "    loss = filterDict[\"loss\"][bs]\n",
    "    epoch = np.arange(loss.size)\n",
    "    plt.plot(epoch, loss)\n",
    "    plt.ylim(minLoss, 2.98)\n",
    "    plt.ylabel('Cross entropy loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    if bs>0:\n",
    "        plt.yticks([])\n",
    "        plt.ylabel('')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
