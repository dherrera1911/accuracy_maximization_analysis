{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c72d73a",
   "metadata": {},
   "source": [
    "#Disparity estimation and effect of batch size\n",
    "\n",
    "Train AMA on the task of disparity estimation. Train two\n",
    "pairs of filters, one after the other (first the model\n",
    "with 2 filters, and then the model with 4 filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9506a410",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### IMPORT PACKAGES\n",
    "##############\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8de5f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### COMMENT THIS CELL WHEN USING GOOGLE COLAB\n",
    "#from ama_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be77a5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### UNCOMMENT THIS CELL FOR GOOGLE COLAB EXECUTION\n",
    "!pip install geotorch\n",
    "import geotorch\n",
    "!pip install git+https://github.com/dherrera1911/accuracy_maximization_analysis.git\n",
    "from ama_library import *\n",
    "!mkdir data\n",
    "!wget -O ./data/AMAdataDisparity.mat https://github.com/burgelab/AMA/blob/master/AMAdataDisparity.mat?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b050a4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### LOAD AMA DATA\n",
    "##############\n",
    "# Load ama struct from .mat file into Python\n",
    "data = spio.loadmat('./data/AMAdataDisparity.mat')\n",
    "# Extract contrast normalized, noisy stimulus\n",
    "s = data.get(\"s\")\n",
    "s = torch.from_numpy(s)\n",
    "s = s.transpose(0,1)\n",
    "s = s.float()\n",
    "# Extract the vector indicating category of each stimulus row\n",
    "ctgInd = data.get(\"ctgInd\")\n",
    "ctgInd = torch.tensor(ctgInd)\n",
    "ctgInd = ctgInd.flatten()\n",
    "ctgInd = ctgInd-1       # convert to python indexing (subtract 1)\n",
    "ctgInd = ctgInd.type(torch.LongTensor)  # convert to torch integer\n",
    "# Extract the values of the latent variable\n",
    "ctgVal = data.get(\"X\")\n",
    "ctgVal = torch.from_numpy(ctgVal)\n",
    "ctgVal = ctgVal.flatten()\n",
    "nPixels = int(s.shape[1]/2)\n",
    "# Extract Matlab trained filters\n",
    "fOri = data.get(\"f\")\n",
    "fOri = torch.from_numpy(fOri)\n",
    "fOri = fOri.transpose(0,1)\n",
    "fOri = fOri.float()\n",
    "# Extract original noise parameters\n",
    "filterSigmaOri = data.get(\"var0\").flatten()\n",
    "maxRespOri = data.get(\"rMax\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e8a72",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### SET TRAINING PARAMETERS FOR FIRST PAIR OF FILTERS\n",
    "##############\n",
    "nFilt = 2   # Number of filters to use\n",
    "filterSigma = float(filterSigmaOri / maxRespOri**2)  # Variance of filter responses\n",
    "nEpochs = 30\n",
    "lrGamma = 0.3   # multiplication factor for lr decay\n",
    "lossFun = nn.CrossEntropyLoss()\n",
    "learningRate = 0.01\n",
    "lrStepSize = 10\n",
    "batchSize = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085506c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "####  TRAIN FIRST PAIR OF FILTERS\n",
    "##############\n",
    "\n",
    "# Define model\n",
    "amaPy = AMA(sAll=s, nFilt=nFilt, ctgInd=ctgInd, filterSigma=filterSigma,\n",
    "        ctgVal=ctgVal)\n",
    "\n",
    "# Put data into Torch data loader tools\n",
    "trainDataset = TensorDataset(s, ctgInd)\n",
    "# Batch loading and other utilities \n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=batchSize,\n",
    "        shuffle=True)\n",
    "# Set up optimizer\n",
    "opt = torch.optim.Adam(amaPy.parameters(), lr=learningRate)  # Adam\n",
    "# Make learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(opt, step_size=lrStepSize,\n",
    "        gamma=lrGamma)\n",
    "#opt = torch.optim.SGD(amaPy.parameters(), lr=0.03)  # SGD\n",
    "# fit model\n",
    "loss, elapsedTimes = fit(nEpochs=nEpochs, model=amaPy,\n",
    "        trainDataLoader=trainDataLoader, lossFun=lossFun, opt=opt,\n",
    "        scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4d084",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## PLOT THE LEARNED FILTERS\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "view_filters_bino(amaPy.f[0,:].detach())\n",
    "plt.subplot(2,2,2)\n",
    "view_filters_bino(amaPy.f[1,:].detach())\n",
    "plt.show()\n",
    "\n",
    "# Print existing parameters names and size\n",
    "for name, param in amaPy.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73562b49",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ADD 2 NEW FILTERS\n",
    "amaPy.add_new_filters(nFiltNew=2)\n",
    "\n",
    "# Plot the set of 4 filters before re-training\n",
    "plt.subplot(2,2,1)\n",
    "view_filters_bino(amaPy.f[0,:].detach())\n",
    "plt.subplot(2,2,2)\n",
    "view_filters_bino(amaPy.f[1,:].detach())\n",
    "plt.subplot(2,2,3)\n",
    "view_filters_bino(amaPy.f[2,:].detach())\n",
    "plt.subplot(2,2,4)\n",
    "view_filters_bino(amaPy.f[3,:].detach())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0becf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## TRAIN THE NEW FILTERS TOGETHER WITH ORIGINAL\n",
    "learningRate2 = learningRate * 1/3\n",
    "nEpochs2 = 30\n",
    "# Re-initializing the optimizer after adding filters is required\n",
    "opt = torch.optim.Adam(amaPy.parameters(), lr=learningRate2)  # Adam\n",
    "loss, elapsedTimes = fit(nEpochs=nEpochs2, model=amaPy,\n",
    "        trainDataLoader=trainDataLoader, lossFun=lossFun, opt=opt,\n",
    "        scheduler=scheduler)\n",
    "\n",
    "# Plot filters after learning\n",
    "plt.subplot(2,2,1)\n",
    "view_filters_bino(amaPy.f[0,:].detach())\n",
    "plt.subplot(2,2,2)\n",
    "view_filters_bino(amaPy.f[1,:].detach())\n",
    "plt.subplot(2,2,3)\n",
    "view_filters_bino(amaPy.f[2,:].detach())\n",
    "plt.subplot(2,2,4)\n",
    "view_filters_bino(amaPy.f[3,:].detach())\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
