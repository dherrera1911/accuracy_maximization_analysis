{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681fa332",
   "metadata": {},
   "source": [
    "# Tutorial of the AMA-Gauss Python package\n",
    "\n",
    "Accuracy Maximization Analysis (AMA) is a **dimensionality reduction**\n",
    "technique that learns a set of optimal linear\n",
    "features to solve a **classification task**,\n",
    "given a **Bayesian decoder** of the filter responses. AMA-Gauss\n",
    "is a variant of AMA that assumes Gaussian conditional distributions\n",
    "of the features (we'll refer to AMA-Gauss as AMA throghout).\n",
    "\n",
    "AMA has been used to train image-computable **ideal observer models**\n",
    "for different visual tasks (estimation of retinal speed,\n",
    "disparity, 3D motion, defocus).\n",
    "Unlike other ideal observer models (i.e. models\n",
    "using optimal probabilistic inference to solve a perceptual task),\n",
    "AMA is image-computable. That is,\n",
    "while most ideal observers receive as input a noisy estimate of\n",
    "the latent variable of interest (without specifying how it is\n",
    "estimated from the raw input), AMA receives the raw\n",
    "high-dimensional image and uses it to estimate the latent variable.\n",
    "\n",
    "Unlike other models used to learn optimal sensory\n",
    "encodings of natural image statistics which use efficient\n",
    "coding, or reconstruction error (e.g. sparse coding), AMA learns the\n",
    "optimal encoding to solve a specific sensory tasks.\n",
    "\n",
    "Here we introduce a PyTorch implementation of AMA, trained through\n",
    "gradient descent.\n",
    "We present the mathematical formalism of the model and the different\n",
    "components of AMA class that allow it to solve a task.\n",
    "As an study case, we train AMA on the task of disparity estimation from\n",
    "binocular images.\n",
    "\n",
    "## Basic structure of AMA-Gauss\n",
    "\n",
    "Let $\\mathbf{s}_{i,j} \\in \\mathbb{R}^d$ be an input stimulus\n",
    "(e.g. a binocular image) that is the $i^{th}$ stimulus associated\n",
    "the true value $X_j$ of the latent variable $X$\n",
    "(e.g. the disparity of the image).\n",
    "The latent variable can take values (e.g. a given disparity value in\n",
    "arc min) from a set ${X_1, X_2, ..., X_k}$.\n",
    "The goal of AMA is to compute the\n",
    "posterior probability distribution over $X$, which can be used to read out\n",
    "an estimate of the latent variable for the input image. This will be made\n",
    "clearer below.\n",
    "\n",
    "The AMA-Gauss model consists of 3 stages:\n",
    "\n",
    "1. Stimulus pre-processing (retinal noise + divisive normalization)\n",
    "1. Linear filtering\n",
    "1. Probabilistic decoding of the latent variable\n",
    "\n",
    "**1)** Add a sample of white noise\n",
    "$\\gamma \\in \\mathbb{R}^d, \\gamma \\sim \\mathcal{N}\\left(0,\\sigma_s^2 \\right)$\n",
    "to the stimulus, to simulate noisy sensory receptors.\n",
    "Then normalize to unit lenght:\n",
    "\\begin{equation}\n",
    "  \\mathbf{c}_{i,j} = \\frac{\\mathbf{s}_{i,j}+\\mathbf{\\gamma}}{\\lVert\n",
    "      \\mathbf{s}_{i,j}+ \\mathbf{\\gamma} \\rVert}\n",
    "\\end{equation}\n",
    "\n",
    "**2)** Apply a set of noisy linear filters\n",
    "$\\mathbf{f} \\in \\mathbb{R}^{n \\times d}$ to\n",
    "the contrast-normalized stimulus, obtaining a population response vector\n",
    "$\\mathbf{R}_{i,j} \\in \\mathbb{R}^n$:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\mathbf{R}_{i,j} = \\mathbf{f} \\cdot \\mathbf{c}_{i,j} + \\eta\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta \\in \\mathbb{R}^n, \\eta \\sim \\mathcal{N}\\left(0, \\sigma_0^2 \\right)$\n",
    "is a sample of white noise.\n",
    "\n",
    "**3)** Given the filter responses, compute the posterior probabilities\n",
    "of each value of the latent variable, $P(X=X_m|\\mathbf{R}_{i,j})$. For this,\n",
    "compute the likelihood functions \n",
    "$L(X=X_m;\\mathbf{R}_{i,j}) = P(\\mathbf{R}_{i,j}|X_m)$\n",
    "(details will be given below), and combine them with\n",
    "the class priors $P(X_m)$:\n",
    "\n",
    "\\begin{equation}\n",
    "  P(X=X_m|\\mathbf{R}_{i,j}) = L(X=X_m; \\mathbf{R}_{i,j}) P(X=X_m)\n",
    "\\end{equation}\n",
    "\n",
    "In this tutorial, we use the AMA model on a set of binocular images to solve\n",
    "the task of estimating disparity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4ae71",
   "metadata": {},
   "source": [
    "## 1) Import and visualize the data\n",
    "\n",
    "We first download and import the binocular images and their\n",
    "disparity values from the [Burge lab](http://burgelab.psych.upenn.edu/) GitHub page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f94c45",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### IMPORT PACKAGES\n",
    "##############\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e7f37",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### DOWNLOAD DISPARITY DATA\n",
    "!mkdir data\n",
    "!wget -O ./data/dspCtg.csv https://raw.githubusercontent.com/dherrera1911/accuracy_maximization_analysis/master/data/dspCtg.csv\n",
    "!wget -O ./data/dspStim.csv https://raw.githubusercontent.com/dherrera1911/accuracy_maximization_analysis/master/data/dspStim.csv\n",
    "!wget --no-check-certificate -O  ./data/dspVal.csv https://raw.githubusercontent.com/dherrera1911/accuracy_maximization_analysis/master/data/dspVal.csv\n",
    "!wget --no-check-certificate -O  ./data/dspFilters.csv https://raw.githubusercontent.com/dherrera1911/accuracy_maximization_analysis/master/data/dspFilters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680089b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### LOAD DISPARITY DATA\n",
    "##############\n",
    "# Load data from csv files\n",
    "# Load stimuli\n",
    "s = torch.tensor(np.loadtxt('./data/dspStim.csv', delimiter=','))\n",
    "s = s.transpose(0,1)\n",
    "s = s.float()\n",
    "nPixels = int(s.shape[1]/2)\n",
    "# Load the category of each stimulus\n",
    "ctgInd = np.loadtxt('./data/dspCtg.csv', delimiter=',')\n",
    "ctgInd = torch.tensor(ctgInd, dtype=torch.int64) - 1\n",
    "# Load the latent variable values\n",
    "ctgVal = torch.tensor(np.loadtxt('./data/dspVal.csv', delimiter=','))\n",
    "ctgVal = ctgVal.float()\n",
    "# Load optimal pre-learned filters\n",
    "fOpt = torch.tensor(np.loadtxt('./data/dspFilters.csv', delimiter=','))\n",
    "fOpt = fOpt.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac013762",
   "metadata": {},
   "source": [
    "We loaded the binocular images into variable `s`. \n",
    "These stimuli are vertically-averaged images, and so they are\n",
    "1D binocular images (see Burge and Geisler JoV 2014 for details).\n",
    "The first half of the columns in `s` contain the left eye image,\n",
    "and the second half contain the right eye image.\n",
    "\n",
    "We loaded into variable `ctgInd` a vector containing the index $j$ of the\n",
    "true level $X_j$ of the latent variable $X$ associated with each stimulus.\n",
    "In `ctgVal` we loaded the set of possible levels\n",
    "that $X$ can take.\n",
    "\n",
    "Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6624f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Image dataset s has {s.shape[0]} images, of {s.shape[1]} pixels each ({nPixels} pixels per monocular image)')\n",
    "print(f'ctgInd is a vector of length {len(ctgInd)}, with the category index of each s')\n",
    "print(f'ctgVal is a vector of length {len(ctgVal)} containing the possible values of X')\n",
    "print(f'ctgVal ranges between {min(ctgVal)} and {max(ctgVal)} arcmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3742ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#### PLOT A STIMULUS\n",
    "##############\n",
    "\n",
    "# Define function to plot binocular stimulus\n",
    "def plot_binocular(bino):\n",
    "    nPixels = int(bino.shape[0]/2)\n",
    "    x = np.linspace(-30, 30, nPixels)\n",
    "    # Plot the binocular 1D images\n",
    "    plt.rcParams.update({'font.size': 14})  # increase default font size\n",
    "    arcMin = np.linspace(start=-30, stop=30, num=nPixels) # x axis values\n",
    "    # Plot the binocular 1D images\n",
    "    plt.plot(x, bino[:nPixels], label='Left eye', color='red')  # plot left eye\n",
    "    plt.plot(x, bino[nPixels:], label='Right eye', color='blue')  #plot right eye\n",
    "    plt.xlabel('Visual field (arcmin)')\n",
    "\n",
    "# Get the disparity value\n",
    "pltInd = 2011 # index of the stimulus to plot\n",
    "stimCategoryInd = ctgInd[pltInd]  # select category index (j) for this stim\n",
    "stimDisparity = ctgVal[stimCategoryInd].numpy()  # Get value of the category (X_j)\n",
    "# Plot the binocular 1D images\n",
    "plt.rcParams.update({'font.size': 14})  # increase default font size\n",
    "arcMin = np.linspace(start=-30, stop=30, num=nPixels) # x axis values\n",
    "# Plot the binocular 1D images\n",
    "plot_binocular(s[pltInd,:])\n",
    "plt.ylabel('Weber contrast')\n",
    "plt.title(f'Stimulus {pltInd}, Disparity={stimDisparity} arc min disparity')\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(7,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f9e029",
   "metadata": {},
   "source": [
    "Next, we will see how the AMA model estimates the latent variable\n",
    "(disparity) from the stimulus `s`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e53aa01",
   "metadata": {},
   "source": [
    "## 2) Download AMA library and initialize AMA object\n",
    "\n",
    "The ama_library can be found in\n",
    "https://github.com/dherrera1911/accuracy_maximization_analysis.\n",
    "We download and import the library below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba2e40",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# FIRST WE NEED TO DOWNLOAD AND INSTALL GEOTORCH AND QUADRATIC RATIOS PACKAGES\n",
    "!pip install geotorch\n",
    "import geotorch\n",
    "!pip install git+https://github.com/dherrera1911/quadratic_ratios.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f9fa27",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# INSTALL THE AMA_LIBRARY PACKAGE FROM GITHUB\n",
    "!pip install git+https://github.com/dherrera1911/accuracy_maximization_analysis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455155c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# IMPORT AMA LIBRARY\n",
    "##############\n",
    "import ama_library.ama_class as cl\n",
    "import ama_library.utilities as au\n",
    "import ama_library.plotting as ap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dc1ed",
   "metadata": {},
   "source": [
    "The ama_class module implements the AMA class, which\n",
    "is built on top of PyTorch's nn.Module. To initialize an AMA\n",
    "object we need to specify the following parameters:\n",
    "\n",
    "* Number of filters: $n$ in the equations, `nFilt` input\n",
    "* Pixel noise variance: $\\sigma_s^2$ in the equations, `pixelCov` input\n",
    "* Response noise variance: $\\sigma_0^2$ in the equations, `respNoiseVar` input\n",
    "\n",
    "We also need to pass the training dataset\n",
    "($\\mathbf{s}$, the vector with associated indexes\n",
    "$j$, and the latent variable values $X_j$).\n",
    "This is in order to compute the stimulus statistics, which are used for\n",
    "inference and training. \n",
    "\n",
    "Let's initialize the AMA model (details about the inputs to AMA\n",
    "initialization can be found in the\n",
    "[AMA GitHub](https://github.com/dherrera1911/accuracy_maximization_analysis/blob/master/ama_library/ama_class.py)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb818ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# INITIALIZE AMA MODEL\n",
    "##############\n",
    "# Set the parameters\n",
    "nFilt = 2  # Create the model with 2 filters\n",
    "pixelNoiseVar = 0.001  # Input pixel noise variance\n",
    "respNoiseVar = 0.001  # Filter response noise variance\n",
    "# Create the untrained AMA object\n",
    "ama = cl.AMA_emp(sAll=s, ctgInd=ctgInd, nFilt=nFilt,\n",
    "        respNoiseVar=respNoiseVar, pixelCov=pixelNoiseVar, ctgVal=ctgVal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e8ee2",
   "metadata": {},
   "source": [
    "The model is initialized with random filters. To better illustrate\n",
    "the model, let's change those for pre-trained optimal filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750796e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change random initialization to optimal filters\n",
    "ama.assign_filter_values(fNew=fOpt)\n",
    "ama.update_response_statistics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad67d9",
   "metadata": {},
   "source": [
    "The filters in the model are in the attribute `f`. Let's plot\n",
    "the optimal filters that we put into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0078c91",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "# VISUALIZE MODEL FILTERS\n",
    "##############\n",
    "fPlot = ama.f.detach().clone()\n",
    "plt.subplot(1,2,1)\n",
    "plot_binocular(fPlot[0,:])\n",
    "plt.ylabel('Weight')\n",
    "plt.title(f'Filter 1')\n",
    "plt.ylim(-0.4, 0.4)\n",
    "plt.subplot(1,2,2)\n",
    "plot_binocular(fPlot[1,:])\n",
    "plt.title(f'Filter 2')\n",
    "plt.ylim(-0.4, 0.4)\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b59151",
   "metadata": {},
   "source": [
    "## 3) Get AMA responses and decode latent variable\n",
    "\n",
    "Next, we show some basic functionalities of the class, to obtain\n",
    "the response to a stimulus and the corresponding latent variable\n",
    "estimate.\n",
    "\n",
    "The AMA model class has different functions for the different processing\n",
    "steps mentioned in the introduction to this notebook:\n",
    "1. Stimulus pre-processing (retinal noise + divisive normalization)\n",
    "1. Linear filtering\n",
    "1. Probabilistic decoding of the latent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da254ddd",
   "metadata": {},
   "source": [
    "### PREPROCESSING\n",
    "The function `ama.preprocess()` implements the preprocessing step\n",
    "mentioned above. In this case the preprocessing consists of adding\n",
    "a sample of noise and normalizing the stimulus to unit norm, but\n",
    "other stimulus pre-processing routines can be implemented (e.g.\n",
    "narrowband normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3ee4f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's apply the pre-processing to our dataset\n",
    "sPre = ama.preprocess(s=s)\n",
    "\n",
    "# Let's check that the stimulus has unit norm as expected\n",
    "print(f'Norm of stimulus before preprocessing: {torch.norm(s[0,:])}')\n",
    "print(f'Norm of stimulus after preprocessing: {torch.norm(sPre[0,:])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c36e9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And lets plot one raw stimulus and its pre-processed version\n",
    "plt.subplot(1,2,1)\n",
    "plot_binocular(s[pltInd,:])\n",
    "plt.ylabel('Weber contrast')\n",
    "plt.title(f'Raw stimulus')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plot_binocular(sPre[pltInd,:])\n",
    "plt.ylabel('Weber contrast')\n",
    "plt.title(f'Pre-processed stimulus')\n",
    "plt.legend()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b3a2d",
   "metadata": {},
   "source": [
    "### FILTERING\n",
    "The method `ama.get_responses()` implements the filtering step,\n",
    "and returns the responses of the filters to a stimulus. \n",
    "This function also applies the pre-processing step, so it takes\n",
    "as input the raw stimulus s, and returns the filter responses.\n",
    "Let's get the responses to the stimuli in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6895dd6c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resp = ama.get_responses(s=s).detach()\n",
    "print(f'Responses shape: {resp.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e0c40",
   "metadata": {},
   "source": [
    "Because we only have 2 filters in the model, we can visualize a\n",
    "response as a point in 2D space. Let's plot the responses to\n",
    "all stimuli in two different classes. Let's also plot the response\n",
    "to the stimulus we plotted above as a black point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76f08da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indPlot1 = ctgInd[pltInd]  # Index of the first class to plot (use same as stim plotted above)\n",
    "indPlot2 = 12  # Index of the second class to plot\n",
    "respClass1 = resp[ctgInd==indPlot1, :]  # Get responses of class 1\n",
    "respClass2 = resp[ctgInd==indPlot2, :]  # Get responses of class 2\n",
    "\n",
    "plt.scatter(respClass1[:,0], respClass1[:,1], label=f'{ctgVal[indPlot1]} arcmin',\n",
    "            color='green', alpha=0.5)\n",
    "plt.scatter(respClass2[:,0], respClass2[:,1], label=f'{ctgVal[indPlot2]} arcmin',\n",
    "            color='brown', alpha=0.5)\n",
    "plt.scatter(resp[pltInd,0], resp[pltInd,1], label=f'Plotted stimulus', \n",
    "            color='black', s=100)\n",
    "plt.legend()\n",
    "plt.xlabel('Filter 1 response')\n",
    "plt.ylabel('Filter 2 response')\n",
    "plt.title('Responses to different stimuli')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a3327",
   "metadata": {},
   "source": [
    "Note that in the plot above each point shows a different stimulus in the\n",
    "dataset. We that the responses to stimuli of the same latent variable\n",
    "value (same color) are clustered together into a Gaussian-like cloud of points. \n",
    "We also see that the responses to the two classes are well separated.\n",
    "The decoding uses the segregation of responses to decode the latent variable\n",
    "(i.e. from the plot above, we can estimate what class the black dot\n",
    "corresponds to).\n",
    "\n",
    "To implement the probabilistic decoding, the model\n",
    "approximates the conditional response distributions\n",
    "of each class as Gaussian distributions, and uses them to decode the\n",
    "latent variable value from the filter responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b8bae",
   "metadata": {},
   "source": [
    "### DECODING\n",
    "The ama object saves in its attributes the response statistics\n",
    "(mean and covariance) conditional on each level of the latent variable.\n",
    "These are used to decode the latent variable from the filter responses.\n",
    "Lets plot the Gaussians in the attributes `ama.respMean` and\n",
    "`ama.respCov` for the responses to the two classes we plotted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e928e7b6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot an ellipse of the 95% confidence interval of the response distribution\n",
    "# for the two classes plotted above.\n",
    "\n",
    "# First plot the responses like above\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.scatter(respClass1[:,0], respClass1[:,1], label=f'{ctgVal[indPlot1]} arcmin',\n",
    "            color='green', alpha=0.5)\n",
    "plt.scatter(respClass2[:,0], respClass2[:,1], label=f'{ctgVal[indPlot2]} arcmin',\n",
    "            color='brown', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('Filter 1 response')\n",
    "plt.ylabel('Filter 2 response')\n",
    "plt.title('Fitted Gaussians and response scatter')\n",
    "\n",
    "# Get the response statistics for the two classes\n",
    "respMean1 = ama.respMean[indPlot1, :].detach()\n",
    "respCov1 = ama.respCov[indPlot1, :, :].detach()\n",
    "respMean2 = ama.respMean[indPlot2, :].detach()\n",
    "respCov2 = ama.respCov[indPlot2, :, :].detach()\n",
    "\n",
    "# Plot the ellipses of the fitted Gaussians\n",
    "ap.plot_ellipse(mean=respMean1, cov=respCov1, ax=ax, color='green')\n",
    "ap.plot_ellipse(mean=respMean2, cov=respCov2, ax=ax, color='brown')\n",
    "# Show figure\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6895a4",
   "metadata": {},
   "source": [
    "As mentioned above, there are 19 different levels of the latent variable.\n",
    "Lets plot the Gaussian ellipses for all the levels of the latent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e767717",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First plot the responses like above\n",
    "ax = plt.subplot(1,1,1)\n",
    "plt.xlabel('Filter 1 response')\n",
    "plt.ylabel('Filter 2 response')\n",
    "plt.title('Fitted Gaussians')\n",
    "# Function that plots many ellipses\n",
    "ap.plot_ellipse_set(mean=ama.respMean, cov=ama.respCov, ax=ax,\n",
    "                    ctgVal=ctgVal, colorMap='jet')\n",
    "# Add color legend\n",
    "ap.add_colorbar(ax=ax, ctgVal=ctgVal, colorMap='jet', label='Disparity (arcmin)')\n",
    "# Set limits\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.xticks([-1, 0, 1])\n",
    "plt.yticks([-1, 0, 1])\n",
    "# Show figure\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8,6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e242fca",
   "metadata": {},
   "source": [
    "We see that similar levels of the latent variable have similar response\n",
    "statistics. Also, the responses differ mostly on their second-order\n",
    "statistics (i.e. the covariance matrix), and not on their first-order\n",
    "statistics (i.e. the mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e0d59",
   "metadata": {},
   "source": [
    "Approximating the latent-variable-conditional response distributions as\n",
    "Gaussian, and using the response mean and covariance of each\n",
    "level $j$ ($\\mu_j$ and $\\Sigma_j$ respectively), the likelihood of\n",
    "the latent variable is given by\n",
    "\n",
    "\\begin{equation}\n",
    "    L(X=X_j;\\mathbf{R}) = P(\\mathbf{R} | X=X_j) =\n",
    "    \\frac{1}{\\sqrt{(2\\pi)^n |\\mathbf{\\Psi_j}|}}\n",
    "    \\exp\\left( -\\frac{1}{2} (\\mathbf{R}-\\boldsymbol{\\mu}_j)^T\n",
    "    \\mathbf{\\Psi}_j^{-1} (\\mathbf{R}-\\boldsymbol{\\mu}_j) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Using Bayes' rule, we can then obtain the posterior probability of\n",
    "each class given the filter responses:\n",
    "\n",
    "\\begin{equation}\n",
    "  P(X=X_j | \\mathbf{R}) = \\frac{P(\\mathbf{R} | X=X_j) P(X=X_j)}{\\sum_{i=1}^{i=k}\n",
    "          P(\\mathbf{R} | X=X_i) P(X=X_i)}\n",
    "\\end{equation}\n",
    "\n",
    "The AMA class has different methods to obtain the likelihoods and the\n",
    "posteriors for a stimulus. The methods `ama.get_ll(s=s)`\n",
    "and `ama.get_posteriors(s=s)` return the log-likelihoods and the\n",
    "posteriors respectively for a set of stimuli `s`. Alternatively,\n",
    "`ama.resp_2_ll(resp=resp)` and `ama.ll_2_posterior(resp=resp)`\n",
    "convert the responses into log-likelihoods, and log-likelihoods\n",
    "into posteriors respectively.\n",
    "We use the former method to obtain the posteriors\n",
    "for the stimuli in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8206e48d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the posteriors for the stimuli in the dataset\n",
    "posteriors = ama.get_posteriors(s=s).detach()\n",
    "print(f'Posteriors shape: {posteriors.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20585c16",
   "metadata": {},
   "source": [
    "We next plot the posterior probability distribution across all levels of\n",
    "the latent variable for all stimuli in the two classes analyzed above.\n",
    "We also show the mean posterior for each class, and the true value\n",
    "of the latent variable. The different shapes of the posterior\n",
    "tell us about the uncertainty of the model about the latent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c07286",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the mean posterior for each class\n",
    "pMean1 = posteriors[ctgInd==indPlot1, :].mean(dim=0)\n",
    "pMean2 = posteriors[ctgInd==indPlot2, :].mean(dim=0)\n",
    "\n",
    "# Plot the posteriors for the two classes plotted above\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(ctgVal, posteriors[ctgInd==indPlot1, :].transpose(0,1),\n",
    "        color='green', alpha=0.2)\n",
    "plt.plot(ctgVal, pMean1, color='black', linewidth=4)\n",
    "plt.axvline(x=ctgVal[indPlot1], linewidth=3, linestyle='--', color='black')\n",
    "plt.xlabel('Disparity (arcmin)')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title(f'Posterior for {ctgVal[indPlot1]} arcmin')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(ctgVal, posteriors[ctgInd==indPlot2, :].transpose(0,1),\n",
    "        color='brown', alpha=0.2)\n",
    "plt.plot(ctgVal, pMean2, color='black', linewidth=4)\n",
    "plt.axvline(x=ctgVal[indPlot2], linewidth=3, linestyle='--', color='black')\n",
    "plt.xlabel('Disparity (arcmin)')\n",
    "plt.ylabel('Posterior probability')\n",
    "plt.title(f'Posterior for {ctgVal[indPlot2]} arcmin')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(11,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367a76ec",
   "metadata": {},
   "source": [
    "Finally, we can use the posterior distributions to obtain an estimate\n",
    "of the latent variable. Like before, the AMA class has two methods to\n",
    "obtain estimates, `ama.get_estimates(s=s)` that takes as input a set of\n",
    "stimuli, and `ama.posterior_2_estimate(posteriors=posteriors)` to\n",
    "convert an array of posteriors to estimates.\n",
    "For this, AMA uses the attribute `ctgVal` that was given at initialization.\n",
    "The default method for obtaining estimates is the *Maximum A Posteriori*\n",
    "(MAP) estimate, which returns the value of the latent variable with\n",
    "the highest posterior probability.\n",
    "\n",
    "Below, we plot the mean estimate for each category of the latent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe9c260",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the estimates for each stimulus\n",
    "estim = ama.get_estimates(s=s).detach()\n",
    "print(f'Disparity estimated for 5 first stimuli: {estim[0:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a92010",
   "metadata": {},
   "source": [
    "Lets plot the mean estimate for each category of the latent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c878f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the posteriors for the two classes plotted above\n",
    "estimStats = au.get_estimate_statistics(estimates=estim, ctgInd=ctgInd)\n",
    "# Plot the mean estimates for each class\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ctgVal, estimStats['estimateMean'])\n",
    "plt.fill_between(ctgVal, estimStats['lowCI'], estimStats['highCI'],\n",
    "        color='blue', alpha=0.2, label='95% CI')\n",
    "ax.axline((0, 0), slope=1, color='black')\n",
    "plt.ylim(ctgVal.min(), ctgVal.max())\n",
    "plt.ylabel('Mean estimated disparity (arcmin)')\n",
    "plt.xlabel('True disparity (arcmin)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
