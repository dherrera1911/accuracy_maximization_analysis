import numpy as np
import torch
from torch import optim
from torch import fft as fft
import torch.nn.functional as F
import matplotlib.pyplot as plt
from matplotlib import patches, colors, cm
from ama_library import quadratic_moments as qm
import time

##################################
##################################
#
## FUNCTIONS FOR FITTING AMA MODELS
#
##################################
##################################
#
# This group of functions take an ama model, and some inputs
# such as the loss function, and do the training loop.
# Different types of training are available, such as training
# the filters in pairs, or with multiple seeds


# Define loop function to train the model
def fit(nEpochs, model, trainDataLoader, lossFun, opt, sAll,
        ctgInd, scheduler=None, addStimNoise=True, addRespNoise=True):
    """
    Fit AMA model using the posterior distribuions generated by the model.
    #
    Arguments:
    - Epochs: Number of epochs. Integer.
    - model: AMA model object.
    - trainDataLoader: Data loader generated with torch.utils.data.DataLoader.
    - lossFun: Loss function that uses posterior distribution over classes.
    - opt: Optimizer, selected from torch.optim.
    - sAll: Full stimulus matrix, used for updating model statistics.
        For Isotropic AMA, it is raw stimuli. For Empirical AMA it is
        noisy normalized stimulus. (nStim x nDim)
    - ctgInd: Vector indicating category of each stimulus row. Used for
            updating statistics (nStim)
    - scheduler: Scheduler for adaptive learning rate, generated with optim.lr_scheduler.
            Default is None.
    - addStimNoise: Boolean indicating whether to add stimulus noise during
            training. Default is True.
    - addRespNoise: Boolean indicating whether to add response noise during
            training. Default is True.
    """
    trainingLoss = np.zeros(nEpochs+1)
    elapsedTime = np.zeros(nEpochs+1)
    # Get the loss of the full dataset stored in the data loader
    trainingLoss[0] = lossFun(model, trainDataLoader.dataset.tensors[0],
            trainDataLoader.dataset.tensors[1]).detach()
    print('Initial loss: ', trainingLoss[0])
    opt.zero_grad()
    # If narrowband, precompute amplitude spectrum for more speed
    if model.filtNorm == 'narrowband':
        sAmp = model.compute_normalized_stimulus_amplitude_spec(s=sAll,
                sameAsInit=True)
    else:
        sAmp = None
    # Measure time and start loop
    start = time.time()
    for epoch in range(nEpochs):
        for sb, ctgb in trainDataLoader:
            # Generate predictions for batch sb, returned by trainDataLoader 
            model.update_response_statistics(sAll=sAll, ctgInd=ctgInd, sAmp=sAmp)
            loss = lossFun(model, sb, ctgb)     # Compute loss
            loss.backward()                     # Compute gradient
            opt.step()                          # Take one step
            opt.zero_grad()                     # Restart gradient
        # Print model loss
        trainingLoss[epoch+1] = lossFun(model, trainDataLoader.dataset.tensors[0],
                trainDataLoader.dataset.tensors[1]).detach()
        trainingDiff = trainingLoss[epoch+1] - trainingLoss[epoch]
        print('Epoch: %d |  Training loss: %.4f  |  Loss change: %.4f' %
                (epoch+1, trainingLoss[epoch+1], trainingDiff))
        end = time.time()
        elapsedTime[epoch+1] = end - start
        # Apply scheduler step
        if not scheduler == None:
            if "ReduceLROnPlateau" in str(type(scheduler)):
                scheduler.step(trainingLoss[epoch+1])    # adapt learning rate
            else:
                scheduler.step()
    # Do the final response statistics update
    model.update_response_statistics(sAll=sAll, ctgInd=ctgInd, sAmp=sAmp)
    return trainingLoss, elapsedTime


# LOOP TO TRAIN MULTIPLE SEEDS AND CHOOSE BEST
def fit_multiple_seeds(nEpochs, model, trainDataLoader, lossFun, opt_fun,
        sAll, ctgInd,  nSeeds=1, scheduler_fun=None, addStimNoise=True,
        addRespNoise=True, sAmp=None):
    """
    Fit AMA model multiple times from different seeds, and keep the result with
    best performance.
    #
    Inputs:
    - nEpochs: Number of epochs for each pair of filters. Integer.
    - model: AMA model object.
    - trainDataLoader: Data loader generated with torch.utils.data.DataLoader.
    - lossFun: Loss function that uses posterior distribution over classes.
    - opt_fun: A function that takes in a model and returns an optimizer.
    - sAll: Full stimulus matrix, used for computing pairwise
            correlations. (nStim x nDim)
    - ctgInd: Vector indicating category of each stimulus row. (nStim)
    - nSeeds: Number of times to train the filters among which to choose
            the best ones. Default is 1.
    - scheduler_fun: Function that takes in an optimizer and returns
            a scheduler for that optimizer. Default is None.
    - addStimNoise: Boolean indicating whether to add stimulus noise during
            training. Default is True.
    - addRespNoise: Boolean indicating whether to add response noise during
            training. Default is True.
    - sAmp: Precomputed amplitude spectrum. Used for speed when the model
            filter normalization is set to "narrowband". (nStim x nDim).
            Optional argument, sAmp is coputed in the function if set to None.
    """
    # If narrowband, precompute amplitude spectrum for more speed
    if model.filtNorm == 'narrowband':
        sAmp = model.compute_normalized_stimulus_amplitude_spec(s=sAll,
                sameAsInit=True)
    else:
        sAmp = None
    if (nSeeds>1):
        # Initialize lists to fill
        seedLoss = np.zeros(nSeeds)
        trainingLoss = [None] * nSeeds
        elapsedTimes = [None] * nSeeds
        filters = [None] * nSeeds
        for p in range(nSeeds):
            if (p>0):
                model.reinitialize_trainable(sAll=sAll, ctgInd=ctgInd, sAmp=sAmp)
            # Train the current pair of trainable filters
            opt = opt_fun(model)
            if (scheduler_fun == None):
                scheduler = None
            else:
                scheduler = scheduler_fun(opt)
            # Train random initialization of the model
            trainingLoss[p], elapsedTimes[p] = fit(nEpochs=nEpochs, model=model,
                    trainDataLoader=trainDataLoader, lossFun=lossFun, opt=opt,
                    sAll=sAll, ctgInd=ctgInd, scheduler=scheduler,
                    addStimNoise=addStimNoise, addRespNoise=addRespNoise)
            filters[p] = model.f.detach().clone()
            # Get the final loss of the filters of this seetrainingLossd
            seedLoss[p] = trainingLoss[p][-1]
        # Set the filter with the minimum loss into the model
        minFilt = seedLoss.argmin()
        model.assign_filter_values(fNew=filters[minFilt], sAll=sAll,
                ctgInd=ctgInd, sAmp=sAmp)
        # Return only the training loss history of the best filter
        minLoss = trainingLoss[minFilt]
        minElapsed = elapsedTimes[minFilt]
    else:
        opt = opt_fun(model)
        if (scheduler_fun == None):
            scheduler = None
        else:
            scheduler = scheduler_fun(opt)
        minLoss, minElapsed = fit(nEpochs=nEpochs, model=model,
                trainDataLoader=trainDataLoader, lossFun=lossFun, opt=opt,
                sAll=sAll, ctgInd=ctgInd, scheduler=scheduler,
                addStimNoise=addStimNoise, addRespNoise=addRespNoise)
    return minLoss, minElapsed


# TRAIN MODEL FILTERS IN PAIRS, WITH POSSIBLE SEED SELECTION
def fit_by_pairs(nEpochs, model, trainDataLoader, lossFun, opt_fun,
        nPairs, sAll, ctgInd, scheduler_fun=None, seedsByPair=1,
        addStimNoise=True, addRespNoise=True):
    """
    Fit AMA model training filters by pairs. After a pair is trained, it
    is fixed in place (no longer trainable), and a new set of trainable
    filters is then initialized and trained. Has the option to try different
    seeds for each pair of filters trained, and choosing the best pair
    #
    Inputs:
    - nEpochs: Number of epochs for each pair of filters. Integer.
    - model: AMA model object.
    - trainDataLoader: Data loader generated with torch.utils.data.DataLoader.
    - lossFun: Loss function that uses posterior distribution over classes.
    - opt_fun: A function that takes in a model and returns an optimizer.
    - nPairs: Number of pairs to train. nPairs=1 corresponds to only training
        the filters included in the input model.
    - sAll: Full stimulus matrix, used for computing pairwise
            correlations. (nStim x nDim)
    - ctgInd: Vector indicating category of each stimulus row. (nStim)
    - seedsByPair: Number of times to train each pair from different random
        initializations, to choose the best pair. Default is 1.
    - scheduler_fun: Function that takes in an optimizer and returns
            a scheduler for that optimizer. Default is None.
    - addStimNoise: Boolean indicating whether to add stimulus noise during
            training. Default is True.
    - addRespNoise: Boolean indicating whether to add response noise during
            training. Default is True.
    """
    if model.filtNorm == 'narrowband':
        sAmp = model.compute_normalized_stimulus_amplitude_spec(s=sAll,
                sameAsInit=True)
    else:
        sAmp = None
    trainingLoss = [None] * nPairs
    elapsedTimes = [None] * nPairs
    # Measure time and start loop
    start = time.time()
    for p in range(nPairs):
        # If not the first iteration, fix current filters and add new trainable
        if (p>0):
            model.move_trainable_2_fixed(sAll=sAll, ctgInd=ctgInd, sAmp=sAmp)
        print(f'Pair {p+1}')
        # Train the current pair of trainable filters
        trainingLoss[p], elapsedTimes[p] = fit_multiple_seeds(nEpochs=nEpochs,
                model=model, trainDataLoader=trainDataLoader, lossFun=lossFun,
                opt_fun=opt_fun, sAll=sAll, ctgInd=ctgInd,
                nSeeds=seedsByPair, scheduler_fun=scheduler_fun,
                addStimNoise=addStimNoise, addRespNoise=addRespNoise,
                sAmp=sAmp)
        end = time.time()
        elapsedTime = end - start
        print(f'########## Pair {p+1} trained in {elapsedTime} ##########')
    # Put all the filters into the f model attribute
    fAll = model.fixed_and_trainable_filters().detach().clone()
    model.assign_filter_values(fNew=fAll, sAll=sAll, ctgInd=ctgInd,
            sAmp=sAmp)
    model.add_fixed_filters(fFixed=torch.tensor([]), sAll=sAll,
            ctgInd=ctgInd, sAmp=sAmp)
    return trainingLoss, elapsedTimes


##################################
##################################
#
## LOSS FUNCTIONS
#
##################################
##################################
#
# Define loss functions that take as input AMA model, so
# different outputs can be used with the same fitting functions


def cross_entropy_loss():
    """
    Cross entropy loss for AMA.
    model: AMA model object
    s: input stimuli. tensor shaped batch x features
    ctgInd: true categories of stimuli, as a vector with category index
        type torch.LongTensor"""
    def lossFun(model, s, ctgInd):
        posteriors = model.get_posteriors(s, addStimNoise=F)
        nStim = s.shape[0]
        loss = -torch.mean(posteriors[torch.arange(nStim), ctgInd])
        return loss
    return lossFun


def kl_loss():
    """
    Negative log-likelihood loss for AMA.
    model: AMA model object
    s: input stimuli. tensor shaped batch x features
    ctgInd: true categories of stimuli, as a vector with category index
        type torch.LongTensor"""
    def lossFun(model, s, ctgInd):
        logProbs = F.log_softmax(model.get_log_likelihood(s), dim=1)
        nStim = s.shape[0]
        loss = -torch.mean(logProbs[torch.arange(nStim), ctgInd])
        return loss
    return lossFun


def mse_loss():
    """
    MSE loss for AMA. Computes MSE between the latent variable
    estimate
    model: AMA model object
    s: input stimuli. tensor shaped batch x features
    ctgInd: true categories of stimuli. type torch.LongTensor"""
    mseLoss = torch.nn.MSELoss()
    def lossFun(model, s, ctgInd):
        loss = mseLoss(model.get_estimates(s, method4est='MMSE'),
                model.ctgVal[ctgInd])
        return loss
    return lossFun


def mae_loss():
    """
    MAE loss for AMA. Computes MAE between the latent variable
    estimate 
    model: AMA model object
    s: input stimuli. tensor shaped batch x features
    ctgInd: true categories of stimuli. type torch.LongTensor"""
    mseLoss = torch.nn.L1Loss()
    def lossFun(model, s, ctgInd):
        loss = mseLoss(model.get_estimates(s, method4est='MMSE'),
                model.ctgVal[ctgInd])
        return loss
    return lossFun


##################################
##################################
#
## STIMULUS PROCESSING
#
##################################
##################################


def smp_pos(samplesPerUnit, nSamples, startAtZero=False):
    """
    Returns an array with an equally spaced sample across a given
    dimension. E.g. returns an array with the spatial position value
    of each pixel.
    #
    Arguments:
        - samplesPerUnit: How many samples to take per 1 unit of the dimension
        - nSamples: Total number of samples to take
    Outputs:
        - posUnt: Array with the position of each sample. numpy arrayw
            of size nSamples.
    """
    if nSamples % 2 == 0:
        posMinUnt = -0.5 * nSamples / samplesPerUnit
        posMaxUnt = 0.5 * nSamples / samplesPerUnit - 1/samplesPerUnit
    else:
        posMinUnt = -0.5 * (nSamples-1) / samplesPerUnit
        posMaxUnt = 0.5 * (nSamples-1) / samplesPerUnit
    posUnt = np.linspace(posMinUnt, posMaxUnt, np.max(nSamples));
    if startAtZero:
       posUnt = posUnt-posMinUnt; 
    return posUnt


def cos_window_XYT(patchSizeXYT, diskDiamXYT=np.array([0,0,0])):
    """
    Make a cosine window with a flat top to apply to a stimulus.
    If one dimension is not needed (e.g. images without time), set its size
    to 1. The window will have a diameter equal to the patch size.
    #
    Arguments:
        - patchSizeXYT: Size of patch to apply window to. The resulting
            window will have the same dimensions.
        - diskDiamXYT: Size of flat part of window (i.e. disk full of 1's).
         By default is set to 0, and no flat window is used.
    Outputs:
        - W: 3D window, where rows correspond to Y dimension, columns to
            X dimension, and channel to T dimension.
    """
    if type(patchSizeXYT) is list:
        patchSizeXYT = np.array(patchSizeXYT)
    rampDiamXYT = patchSizeXYT - diskDiamXYT
    Wdim = []
    for dim in range(3):
        dimNumPix = patchSizeXYT[dim]
        # Make flat-top disk in X
        R = smp_pos(1, dimNumPix)
        if R.size % 2 == 0:
            R = R + np.diff(R[0:2])/2
        # Convert diameter to radius
        diskRadiusPix = diskDiamXYT[dim] / 2
        rampRadiusPix = rampDiamXYT[dim] / 2
        freqcpp = 1 / (2 * rampRadiusPix)
        # Make  ramp
        Wtemp = np.ones((dimNumPix, 1))
        mask = np.abs(R) > diskRadiusPix
        Wtemp[mask,0] = 0.5 * (1 + np.cos(2 * np.pi * freqcpp * (np.abs(R[mask]) -
            diskRadiusPix)))
        Wtemp[np.abs(R) > (diskRadiusPix + rampRadiusPix)] = 0
        Wdim.append(Wtemp.squeeze())
    W = np.einsum('x,y,t->yxt', Wdim[0], Wdim[1], Wdim[2])
    return W


def contrast_stim(s, nChannels=1):
    """Take a batch of stimuli and convert to Weber contrast stimulus
    That is, subtracts the stimulus mean, and then divides by the mean.
    Arguments:
    s: Stimuli batch. (nStim x nDimensions)
    nChannels: Channels into which to separate the stimulus to make each
        channel into contrast individually. """
    s_split = torch.chunk(s, nChannels, dim=1)
    s_contrast_split = []
    for s_part in s_split:
        sMean = torch.mean(s_part, axis=1)
        sContrast = torch.einsum('nd,n->nd', (s_part - sMean.unsqueeze(1)), 1/sMean)
        s_contrast_split.append(sContrast)
    sContrast = torch.cat(s_contrast_split, dim=1)
    return sContrast


def noise_total_2_noise_pix(sigmaEqv, numPix):
    """ Calculate the level of noise (i.e. standar deviation) to implement
    decision-variable noise with standard deviation given by sigmaEqv.
    #
    Arguments:
        - sigmaEqv: Standard deviation of decision variable
        - numPix: Number of pixels in the stimulus
    Outputs:
        - sigmaPix: Standard deviation of pixel-level noise
    """
    sigmaPix = sigmaEqv * np.sqrt(numPix)
    return sigmaPix


def normalize_stimuli_channels(s, nChannels=1):
    """ Normalize the stimuli in s to unit norm. Normalize the
    stimuli separating it into nChannels. Each channel is assumed to
    be in contiguous columns of s (that is, s is split into nChannels
    chunks to normalize).
    Arguments:
        - s: Stimuli to normalize. (nStim x nDim)
        - nChannels: Number of channels into which to divide stimuli.
    """
    n, d = s.shape
    # Reshape s to have an extra dimension for the groups
    sReshaped = s.view(n, nChannels, -1)
    # Calculate the norms for each group separately
    group_norms = torch.norm(sReshaped, dim=2, keepdim=True)
    # Normalize the groups separately
    sNormalized = sReshaped / group_norms
    # Compute the overall normalization factor
    normFactor = torch.sqrt(torch.tensor(nChannels))
    # Multiply each row by the normalization factor to make the whole row have unit length
    sNormalized = (sNormalized.view(n, -1) / normFactor).view(n, d)
    return sNormalized


def category_means(s, ctgInd):
    nDim = int(s.shape[1])
    # Compute the mean of the stimuli for each category
    nClasses = np.unique(ctgInd).size
    stimMean = torch.zeros(nClasses, nDim)
    for cl in range(nClasses):
        levelInd = [i for i, j in enumerate(ctgInd) if j == cl]
        stimMean[cl,:] = torch.mean(s[levelInd, :], dim=0)
    return stimMean


def category_secondM(s, ctgInd):
    nDim = int(s.shape[1])
    # Compute the mean of the stimuli for each category
    nClasses = np.unique(ctgInd).size
    stimSM = torch.zeros(nClasses, nDim, nDim)
    for cl in range(nClasses):
        levelInd = [i for i, j in enumerate(ctgInd) if j == cl]
        nStimLevel = len(levelInd)
        stimSM[cl,:,:] = torch.einsum('nd,nb->db', s[levelInd,:],
                s[levelInd,:]) / nStimLevel
    return stimSM


def compute_amplitude_spectrum(s):
    """Compute the amplitude spectrum of a stimulus. Shifted
    to have lower amplitudes in the middle.
    Also divides by the square root of the number of dimension"""
    # Get amplitude spectrum
    sAmp = torch.abs(fft.fftshift(fft.fft(s, dim=1, norm='ortho'), dim=1))
    return sAmp


def interpolate_category_values(ctgVal, nPoints):
    nVals = len(ctgVal) - 1
    interpList = []
    for n in range(nVals):
        interp = np.linspace(ctgVal[n], ctgVal[n+1], num=nPoints+2)
        interpList.append(interp[:-1])
    ctgValInterp = np.concatenate(interpList)
    ctgValInterp = np.append(ctgValInterp, ctgVal[-1])
    return ctgValInterp
    


##################################
##################################
#
## SUMMARIZE MODEL RESULTS
#
##################################
##################################
#
#

# Function that turns posteriors into estimate averages, SDs and CIs
def get_estimate_statistics(estimates, ctgInd, quantiles=[0.025, 0.975]):
    # Compute means and stds for each true level of the latent variable
    estimatesMeans = torch.zeros(ctgInd.max()+1)
    estimatesSD = torch.zeros(ctgInd.max()+1)
    lowCI = torch.zeros(ctgInd.max()+1)
    highCI = torch.zeros(ctgInd.max()+1)
    quantiles = torch.tensor(quantiles)
    for cl in ctgInd.unique():
        levelInd = [i for i, j in enumerate(ctgInd) if j == cl]
        estimatesMeans[cl] = estimates[levelInd].mean()
        estimatesSD[cl] = estimates[levelInd].std()
        (lowCI[cl], highCI[cl]) = torch.quantile(estimates[levelInd], quantiles)
    return {'estimateMean': estimatesMeans, 'estimateSD': estimatesSD,
            'lowCI': lowCI, 'highCI': highCI}


def subsample_covariance(covariance, classInd, filtInd):
    """ Takes a tensor of shape k x d x d holding the covariance
    matrices for k classes and d filters, and returns a smaller
    tensor with the covariances matrices of the classes given in
    classInd, and of the filters in filtInd.
    Eg. if classInd=[2, 3, 4] and filtInd=[0,3], it returns the
    covariance matrix between filters 0 and 3, for classes 2,3,4."""
    covPlt = covariance[classInd, :, :]
    covPlt = covPlt[:, filtInd, :]
    covPlt = covPlt[:, :, filtInd]
    return covPlt


def subsample_categories(nCtg, subsampleFactor):
    """
    Subsample the number of categories, while keeping the middle category.
    Arguments:
        - nCtg: Number of categories
        - subsampleFactor: Factor by which the categories will be subsampled
    Output:
        - subsampledInds: Vector containing the indices of the subsampled categories.
            These are equispaced with one another, and keep the middle category.
    """
    # Generate original vector
    allInds = np.arange(nCtg)
    # Ensure nCtg is odd
    assert len(allInds) % 2 == 1, "nCtg must be odd."
    # Find middle index
    midIdx = len(allInds) // 2
    # Calculate the start index for the left and right subsample
    start_left = midIdx % subsampleFactor
    start_right = midIdx + subsampleFactor
    # Subsample vector, maintaining the middle element
    subsampledInds = np.concatenate((allInds[start_left:midIdx:subsampleFactor], 
                                 allInds[midIdx:midIdx+1], 
                                 allInds[start_right::subsampleFactor]))
    return subsampledInds



##################################
##################################
#
## UTILITY FUNCTIONS
#
##################################
##################################
#
#

def unpack_matlab_data(matlabData):
    # Extract disparity stimuli
    if 's' in matlabData.keys():
      s = matlabData.get("s")
    else:
      s = matlabData.get("Iret")
    s = torch.from_numpy(s)
    s = s.transpose(0, 1)
    s = s.float()
    # Extract the vector indicating category of each stimulus row
    ctgInd = matlabData.get("ctgInd")
    ctgInd = torch.tensor(ctgInd)
    ctgInd = ctgInd.flatten()
    ctgInd = ctgInd-1       # convert to python indexing (subtract 1)
    ctgInd = ctgInd.type(torch.LongTensor)  # convert to torch integer
    # Extract the values of the latent variable
    ctgVal = matlabData.get("X")
    ctgVal = torch.from_numpy(ctgVal)
    ctgVal = ctgVal.flatten().float()
    return (s, ctgInd, ctgVal)


